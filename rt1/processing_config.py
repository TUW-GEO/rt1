"""convenient default functions for use with rt1.rtfits.processfunc()"""

import sys
import traceback
from pathlib import Path
from .rtfits import load
from . import log


class rt1_processing_config(object):
    """
    a class that provides convenient default functions that can be used
    with `rt1.rtprocess.RTprocess`.

    Parameters
    ----------
    save_path : pathlib.Path, optional
        the parent-path where the files should be stored.
        The default is None.
    dumpfolder : str, optional
        the sub-folder in which the dump-files will be stored.
        The default is None.
    finalout_name : srt, optional
        the name of the hdf-file generated by finaloutput().
        The default is None.

    Examples
    --------
    >>> from rt1.processing_config import rt1_processing_config
    ...
    ... class run_configuration(rt1_processing_config):
    ...     def __init__(self, **kwargs):
    ...         super().__init__(**kwargs)
    ...
    ...     # customize the naming of the output-files
    ...     def get_names_ids(self, reader_arg):
    ...         # define the naming-convention of the files etc.
    ...         ...
    ...         names_ids = dict(filename='site_1.dump', feature_id = '1')
    ...         return names_ids
    ...
    ...     # customize the preprocess function
    ...     def preprocess(self, **kwargs):
    ...         # run code prior to the init. of a multiprocessing.Pool
    ...         ...
    ...         return dict(reader_args=[dict(...), dict(...)],
    ...                     pool_kwargs=dict(...),
    ...                     ...)
    ...
    ...     # add a reader-function
    ...     def reader(self, **reader_arg):
    ...         # read the data for each fit
    ...         ...
    ...         return df, aux_data
    ...
    ...     # customize the function that is used to catch exceptions
    ...     def exceptfunc(self, ex, reader_arg):
    ...         # do something with the catched exception ex.args:
    ...         if 'lets catch this exception' in ex:
    ...             ...

    """

    def __init__(self, **kwargs):

        if "save_path" in kwargs and "dumpfolder" in kwargs:
            parentpath = Path(kwargs["save_path"]) / kwargs["dumpfolder"]

            self.rt1_procsesing_dumppath = parentpath / "dumps"
            self.rt1_procsesing_respath = parentpath / "results"
            self.rt1_procsesing_cfgpath = parentpath / "cfg"
        else:
            self.rt1_procsesing_dumppath = None
            self.rt1_procsesing_respath = None
            self.rt1_procsesing_cfgpath = None

        # append all arguments passed as kwargs to the class
        # NOTICE: ALL definitions in the 'PROCESS_SPECS' section of the
        #         config-file will be passed as kwargs to the initialization
        #         of this class!)
        for key, val in kwargs.items():
            setattr(self, key, val)

    def get_names_ids(self, reader_arg):
        """
        A function that returns the file-name based on the passed reader_args

        - by default, the filenames are generated from the reader-argument "ID"

        Parameters
        ----------
        reader_arg : dict
            the arguments passed to the reader function.

        Returns
        -------
        feature_id : str
            the ID that will be assigned to the fits-object (e.g. `fit.ID`)
        filename : str
            the file-name that will be used to save the pickle dump-files
        """

        # the ID used for indexing the processed sites
        feature_id = str(reader_arg["ID"])

        # the filename of the dump-file
        filename = f"{feature_id}.dump"

        return dict(
            feature_id=feature_id,
            filename=filename,
        )

    def preprocess(self, **kwargs):
        """
        a (optional) function that is called PRIOR to processing

        Parameters
        ----------
        kwargs :
            kwargs obtained from

            >>> RTprocess(...).run_processing(preprocess_kwargs=dict(...))

        Returns:
        --------
        dict
            a dict with the following keys defined:

                - "reader_args" : a list of dicts that will be used as input
                  for the call to the reader function (e.g. `reader_arg`)
                - "pool_kwargs" : a dict of kwargs passed to the initialization
                  of the multiprocessing.Pool used for processing
                  (useful for providing initializers etc.)
        --------
        """

        return

    def reader(self, reader_arg):
        """
        a function that is called for each site to obtain the dataset

        it must return a pandas.DataFrame with the following keys defined:
            - "inc" : the incidence-angle in radians
            - "sig" : the backscattering coefficient values

        any additional return-values will be appended to the fit as `fit.aux_data`

        >>> def reader(self, reader_arg):
        >>>    data = pd.DataFrame(inc=[...]
        >>>                        sig=[...],
        >>>                        index = [a datetime-index])
        >>>
        >>>    aux_data = "any aux-data that should be appended"
        >>>
        >>>    return data, aux_data

        Parameters
        ----------
        reader_arg : dict
            the arguments passed to the reader function.

        Returns
        -------
        return_data : pandas.DataFrame
            a pandas.DataFrame that will be used as "dataset" for the fit
            (e.g. `fit.dataset`)
        *aux_data :
            any additional return-arguments will be attached to the fits-object
            as `fit.aux_data`
        """
        assert False, "you must define a proper reader-function first!"

    def exceptfunc(self, ex, reader_arg):
        """
        a error-catch function that handles the following errors:

        - 'rt1_skip'
            exceptions are ignored and the next site is processed WITHOUT
            writing the exception to a file
        - 'rt1_data_error'
            exceptions are ignored and the next site is processed
        - 'rt1_file_already_exists'
            the already existing dump-file is loaded, and the dict defining
            the Fits-object is returned
        - for any other exceptions:
            if `save_path` and `dumpfolder` are specified
            a dump of the exception-message is saved and the exception
            is ignored. otherwise the exception will be raised.

        Parameters
        ----------
        ex : Exception
            the catched exception.
        reader_arg : dict
            the arguments passed to the reader function.

        """

        log.debug(
            f"catched an {type(ex).__name__} {ex.args} for the "
            + f"following reader_args: \n{reader_arg}"
        )

        names_ids = self.get_names_ids(reader_arg)
        raise_exception = True

        if "rt1_skip" in ex.args:
            log.debug("SKIPPED the following error:")
            log.debug(traceback.format_exc())
            # ignore skip exceptions
            raise_exception = False

        elif "rt1_file_already_exists" in ex.args:
            # if a fit-dump file already exists, try loading the existing
            # file and apply post-processing (e.g. avoid re-processing results)
            raise_exception = False

            log.debug(
                f"the file '{names_ids['filename']}' already exists... "
                + "I'm 'using the existing one!"
            )

            try:
                fit = load(self.rt1_procsesing_dumppath / names_ids["filename"])
                return fit._get_fit_to_hdf_dict()
            except Exception:
                log.error(
                    "there has been a problem while loading the "
                    + f"already processed file '{names_ids['filename']}'"
                )
                log.error(traceback.format_exc())

        elif "rt1_data_error" in ex.args:
            # raised if there was a problem with the data, ignore and continue
            raise_exception = False

            log.error(f"there was a DATA-problem for '{names_ids['filename']}'")
        else:
            log.error(
                f"something went wrong for: {reader_arg}\n" + traceback.format_exc()
            )

        # in case `save_path` is specified, write ALL exceptions to a file
        # and continue processing WITHOUT raising the exception.
        # if `save_path`is NOT specified, raise ONLY exceptions that
        # have not been explicitly catched
        if self.rt1_procsesing_dumppath is None and raise_exception is True:
            log.debug(
                "`save_path` must be specified otherwise exceptions "
                + "that are not explicitly catched by `exceptfunc()` "
                + " will be raised!"
            )
            raise ex

        # flush stdout to see output of child-processes
        sys.stdout.flush()
